# FRAMED Test Suite - Verification & Execution Summary

**Date:** 2026-01-24  
**Status:** âœ… Verified, Enhanced, and Ready

---

## âœ… Verification Complete

### Structure Verification

- âœ… All test files created and structured correctly
- âœ… All imports verified and correct
- âœ… All function calls match actual implementations
- âœ… All data structure paths verified
- âœ… Error handling comprehensive
- âœ… Documentation complete

### Robustness Enhancements

1. âœ… **File Validation** - Checks file existence, readability, format
2. âœ… **Category-Specific Validation** - Validates expectations per category
3. âœ… **Enhanced Error Handling** - Comprehensive try-except blocks
4. âœ… **Better Evidence Alignment** - Fixed visual evidence path
5. âœ… **Improved Dataset Loading** - Better error messages, validation

---

## ğŸš€ Execution Steps

### Step 1: Prepare Dataset

```bash
# Create dataset directory structure
mkdir -p test_dataset/{architecture,street,nature,portraits,ambiguous,mixed}

# Copy images into appropriate folders
# Example:
cp your_images/architecture/*.jpg test_dataset/architecture/
cp your_images/street/*.jpg test_dataset/street/
cp your_images/nature/*.jpg test_dataset/nature/
# ... etc
```

**Supported formats:** `.jpg`, `.jpeg`, `.png`, `.webp`, `.tiff`, `.bmp`, `.tif`

### Step 2: Verify Environment

```bash
# From project root
cd framed-clean

# Verify Python version
python --version  # Should be 3.11+

# Verify dependencies
python -c "import torch, transformers, cv2, openai; print('Dependencies OK')"
```

### Step 3: Run Quick Test (10 images)

```bash
# Basic test to verify everything works
python -m framed.tests.test_intelligence_pipeline \
    --dataset_path ./test_dataset \
    --max_images 10 \
    --shuffle \
    --seed 42
```

**Expected output:**
- Test run directory created
- 10 images processed
- Summary, metrics, failures saved
- Console output with progress

### Step 4: Review Results

```bash
# Find the latest run directory
ls -lt framed/tests/test_runs/ | head -2

# View summary
cat framed/tests/test_runs/run_*/summary.json | python -m json.tool

# Check if tests passed
cat framed/tests/test_runs/run_*/summary.json | grep -A 5 "pass_fail_report"
```

### Step 5: Run Full Test (Recommended)

```bash
# Full test with all images
python -m framed.tests.test_intelligence_pipeline \
    --dataset_path ./test_dataset \
    --shuffle \
    --seed 42
```

**Or with expression layer disabled (faster, cheaper):**

```bash
python -m framed.tests.test_intelligence_pipeline \
    --dataset_path ./test_dataset \
    --shuffle \
    --seed 42 \
    --disable_expression
```

---

## ğŸ“Š Understanding Results

### Summary File (`summary.json`)

```json
{
  "test_config": {...},
  "total_images": 100,
  "completed": 100,
  "failed": 5,
  "pass_fail_report": {
    "passed": true,
    "failures": [],
    "warnings": [...]
  }
}
```

**Key indicators:**
- `passed: true` = All hard rules pass âœ…
- `failures: []` = No critical failures âœ…
- `warnings: [...]` = Soft warnings (review but not blocking)

### Metrics File (`metrics.json`)

**Critical thresholds:**
- `hallucination_rate` < 5% âœ…
- `overconfidence_rate` < 3% âœ…
- `reflection_failure_escape_rate` < 10% âœ…
- `uncertainty_acknowledged_percent` > 20% âœ…

### Failures File (`failures.json`)

List of images that failed, with detailed diagnostics for debugging.

---

## ğŸ¯ Test Execution Examples

### Example 1: Development Testing (Fast)

```bash
python -m framed.tests.test_intelligence_pipeline \
    --dataset_path ./test_dataset \
    --max_images 20 \
    --disable_expression \
    --shuffle \
    --seed 42
```

**Time:** ~2-5 minutes  
**Use case:** Quick validation during development

### Example 2: Validation Testing (Medium)

```bash
python -m framed.tests.test_intelligence_pipeline \
    --dataset_path ./test_dataset \
    --max_images 100 \
    --shuffle \
    --seed 42
```

**Time:** ~10-20 minutes  
**Use case:** Pre-deployment validation

### Example 3: Full Benchmark (Comprehensive)

```bash
python -m framed.tests.test_intelligence_pipeline \
    --dataset_path ./test_dataset \
    --shuffle \
    --seed 42
```

**Time:** Depends on dataset size  
**Use case:** Complete benchmark

### Example 4: Reproducible Test (Fixed Seed)

```bash
python -m framed.tests.test_intelligence_pipeline \
    --dataset_path ./test_dataset \
    --max_images 50 \
    --shuffle \
    --seed 42 \
    --run_dir ./results/baseline
```

**Use case:** Baseline for comparison

---

## ğŸ” What Gets Tested

### For Each Image:

1. âœ… **File Validation** - Exists, readable, valid format
2. âœ… **Visual Evidence Extraction** - HSV, texture, spatial analysis
3. âœ… **Full Analysis** - Semantic signals + Intelligence Core
4. âœ… **Core Interpretation** - Primary conclusion, confidence, alternatives
5. âœ… **Evidence Alignment** - Visual vs text, conflicts, hallucination
6. âœ… **Expression Layer** - Poetic critique (optional)
7. âœ… **Reflection Loop** - Self-validation, quality scores
8. âœ… **Learning Impact** - Memory updates, confidence adjustments
9. âœ… **Mentor Integrity** - Flattery, instructions, drift
10. âœ… **Category Validation** - Category-specific expectations

### Aggregate Metrics:

1. âœ… **Intelligence Health** - Confidence, uncertainty, hypotheses
2. âœ… **Failure Metrics** - Hallucination, overconfidence, reflection failures
3. âœ… **Learning Metrics** - Memory growth, corrections, evolution

---

## ğŸ“ Output Location

All results are saved to:

```
framed/tests/test_runs/run_YYYY_MM_DD_HHMMSS/
â”œâ”€â”€ summary.json          # Test summary
â”œâ”€â”€ metrics.json          # Aggregate metrics
â”œâ”€â”€ failures.json         # List of failures
â””â”€â”€ raw/                  # Individual image results
    â”œâ”€â”€ architecture_img001.json
    â”œâ”€â”€ street_img001.json
    â””â”€â”€ ...
```

---

## ğŸ› ï¸ Troubleshooting

### Issue: Import Errors

```bash
# Solution: Run from project root
cd framed-clean
python -m framed.tests.test_intelligence_pipeline --dataset_path ./test_dataset --max_images 10
```

### Issue: No Images Found

```bash
# Solution: Check dataset structure
ls -la test_dataset/
ls -la test_dataset/architecture/

# Verify images have correct extensions
# Supported: .jpg, .jpeg, .png, .webp, .tiff, .bmp, .tif
```

### Issue: Memory Errors

```bash
# Solution: Use smaller test size
python -m framed.tests.test_intelligence_pipeline \
    --dataset_path ./test_dataset \
    --max_images 10 \
    --disable_expression
```

### Issue: Slow Performance

```bash
# Solution: Disable expression layer
python -m framed.tests.test_intelligence_pipeline \
    --dataset_path ./test_dataset \
    --max_images 50 \
    --disable_expression
```

---

## âœ… Pre-Flight Checklist

Before running tests:

- [ ] Dataset directory exists
- [ ] Images are in category folders
- [ ] Images are valid and readable
- [ ] Python 3.11+ installed
- [ ] All dependencies installed
- [ ] Environment variables set (if needed)
- [ ] Output directory is writable

After running tests:

- [ ] Summary file created
- [ ] Metrics file created
- [ ] Failures file created (may be empty)
- [ ] Raw logs directory has files
- [ ] Pass/fail report shows `passed: true`
- [ ] Metrics are within thresholds

---

## ğŸ“š Documentation

- **`framed/tests/README.md`** - User guide
- **`framed/tests/EXECUTION_GUIDE.md`** - Detailed execution instructions
- **`framed/tests/example_usage.py`** - Code examples
- **`framed/tests/TEST_STRUCTURE_VERIFICATION.md`** - Structure verification

---

## ğŸ¯ Quick Reference

### Most Common Commands

```bash
# Quick test (10 images, no expression)
python -m framed.tests.test_intelligence_pipeline \
    --dataset_path ./test_dataset \
    --max_images 10 \
    --disable_expression

# Full test (all images)
python -m framed.tests.test_intelligence_pipeline \
    --dataset_path ./test_dataset \
    --shuffle \
    --seed 42

# Reproducible test (fixed seed)
python -m framed.tests.test_intelligence_pipeline \
    --dataset_path ./test_dataset \
    --max_images 100 \
    --shuffle \
    --seed 42 \
    --run_dir ./results/baseline
```

---

**Status:** âœ… **Test suite verified, enhanced, and ready for execution!**

The test suite is now robust, comprehensive, and ready to stress test FRAMED across all image types and scenarios.
